{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from scipy.sparse import coo_matrixs\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    # 加载数据\n",
    "    data = loadmat(\"mnist_all.mat\")\n",
    "\n",
    "    # print(data.keys())\n",
    "\n",
    "    train_data = pd.DataFrame()\n",
    "    test_data = pd.DataFrame()\n",
    "\n",
    "    for i in range(10):\n",
    "        temp_df = pd.DataFrame(data[\"train\" + str(i)])\n",
    "        temp_df['label'] = i\n",
    "        train_data = train_data.append(temp_df)\n",
    "        temp_df = pd.DataFrame(data[\"test\" + str(i)])\n",
    "        temp_df['label'] = i\n",
    "        test_data = test_data.append(temp_df)\n",
    "\n",
    "    train_data = shuffle(train_data)\n",
    "    test_data = shuffle(test_data)\n",
    "\n",
    "    train_labels = np.array(train_data['label'])\n",
    "    test_labels = np.array(test_data['label'])\n",
    "\n",
    "\n",
    "    train_data = train_data.drop('label', axis=1)\n",
    "    test_data = test_data.drop('label', axis=1)\n",
    "\n",
    "    train_data = np.array(train_data) / 255\n",
    "    test_data = np.array(test_data) / 255\n",
    "\n",
    "    return train_data, test_data, train_labels, test_labels\n",
    "\n",
    "X_train, X_test, y_train, y_test = load_data()\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[5].reshape(1, 28, 28).reshape(28, 28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only for one example\n",
    "class Linear:\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        self.w = np.random.randn(output_dim, input_dim)\n",
    "        self.b = np.random.randn(output_dim, 1)\n",
    "        self.x = None\n",
    "        self.dw = None\n",
    "        self.db = None\n",
    "        \n",
    "        self.type = 'linear'\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        \n",
    "        out = np.dot(self.w, x) + self.b\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        self.dw = np.dot(dout, self.x.T)\n",
    "        self.db = dout\n",
    "        \n",
    "        return np.dot(self.w.T, dout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "        \n",
    "        self.type = 'relu'\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.mask = (x <= 0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        \n",
    "        dout[self.mask] = 0\n",
    "        return dout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    mask = (x <= 0)\n",
    "    out = x.copy()\n",
    "    out[mask] = 0\n",
    "    \n",
    "    return mask, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "class softmax:\n",
    "    def __init__(self):\n",
    "        self.p = None\n",
    "        self.t = None\n",
    "    \n",
    "    def forward(self, a, t):\n",
    "        self.t = t\n",
    "        c = np.max(a)\n",
    "        exp_a = np.exp(a - c)\n",
    "        sum_exp_a = np.sum(exp_a)\n",
    "        p = exp_a / sum_exp_a\n",
    "        \n",
    "        self.p = p\n",
    "        \n",
    "        _p = np.log(p + 1e-5)\n",
    "\n",
    "        loss = np.sum(-_p*t)\n",
    "        \n",
    "        return loss\n",
    "    def backward(self):\n",
    "        \n",
    "        return self.p - self.t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeOneHot(class_num, x):\n",
    "    true = np.zeros(class_num)\n",
    "    true[x] = 1\n",
    "    return true.reshape(class_num, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only for one example\n",
    "class BasicRNN:\n",
    "    def __init__(self, hidden_size, input_size):\n",
    "        self.type = 'basic_rnn'\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.seq_len = None\n",
    "        \n",
    "        self.b1 = np.random.randn(hidden_size, 1)\n",
    "        self.b2 = np.random.randn(input_size, 1)\n",
    "        self.W = np.random.randn(hidden_size, hidden_size)\n",
    "        self.V = np.random.randn(input_size, hidden_size)\n",
    "        self.U = np.random.randn(hidden_size, input_size)\n",
    "        self.x = None\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        self.seq_len = x.shape[0]\n",
    "        self.s = np.zeros((self.seq_len + 1, self.hidden_size))\n",
    "        for i in range(x.shape[0]):\n",
    "            self.s[i] = (np.tanh(np.dot(self.U, x[i].reshape(-1, 1)) + \\\n",
    "                                 np.dot(self.W, self.s[i-1].reshape(-1, 1)) + self.b1)).reshape(self.hidden_size)\n",
    "        \n",
    "        out = np.dot(self.V, self.s[i].reshape(-1, 1)) + self.b2\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        self.dW = np.zeros((self.hidden_size, self.hidden_size))\n",
    "        self.dV = np.zeros((self.input_size, self.hidden_size))\n",
    "        self.dU = np.zeros((self.hidden_size, self.input_size))\n",
    "        self.db1 = np.zeros((self.hidden_size, 1))\n",
    "        self.db2 = np.zeros((self.input_size, 1))\n",
    "        \n",
    "        index = self.seq_len - 1\n",
    "        \n",
    "        delta = np.dot(self.V.T, dout)*(1 - self.s[index].reshape(-1, 1)* self.s[index].reshape(-1, 1))\n",
    "            \n",
    "        self.dV += np.dot(dout, self.s[index].reshape(-1, 1).T)\n",
    "        self.db2 += dout\n",
    "        self.db1 += delta\n",
    "        \n",
    "        self.dW += np.dot(delta, self.s[index-1].reshape(-1, 1).T)\n",
    "        self.dU += np.dot(delta, self.x[index].reshape(-1, 1).T)\n",
    "        \n",
    "        index -= 1\n",
    "        while index >= 0:\n",
    "            delta = np.dot(self.W.T, delta) * (1 - self.s[index].reshape(-1, 1) * self.s[index].reshape(-1, 1))\n",
    "            \n",
    "            self.db1 += delta\n",
    "            self.dW += np.dot(delta, self.s[index-1].reshape(-1, 1).T)\n",
    "            self.dU += np.dot(delta, self.x[index].reshape(-1, 1).T)\n",
    "            \n",
    "            index -= 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class BasicRNN:\n",
    "#     def __init__(self, hidden_size, input_size):\n",
    "#         self.type = 'basic_rnn'\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.input_size = input_size\n",
    "#         self.seq_len = None\n",
    "        \n",
    "#         self.b1 = np.random.randn(hidden_size, 1)\n",
    "#         self.b2 = np.random.randn(input_size, 1)\n",
    "#         self.W = np.random.randn(hidden_size, hidden_size)\n",
    "#         self.V = np.random.randn(input_size, hidden_size)\n",
    "#         self.U = np.random.randn(hidden_size, input_size)\n",
    "#         self.x = None\n",
    "#         self.masks= None\n",
    "#     def forward(self, x):\n",
    "#         self.x = x\n",
    "#         self.seq_len = x.shape[0]\n",
    "#         self.s = np.zeros((self.seq_len + 1, self.hidden_size))\n",
    "#         self.masks = []\n",
    "#         for i in range(x.shape[0]):\n",
    "#             temp_mask, temp_s_i = relu(np.dot(self.U, x[i].reshape(-1, 1)) + \\\n",
    "#                                  np.dot(self.W, self.s[i-1].reshape(-1, 1)) + self.b1)\n",
    "                 \n",
    "#             self.s[i] = temp_s_i.reshape(self.hidden_size) \n",
    "#             self.masks.append(temp_mask.reshape(self.hidden_size))\n",
    "#         out = np.dot(self.V, self.s[i].reshape(-1, 1)) + self.b2\n",
    "        \n",
    "#         return out\n",
    "    \n",
    "#     def backward(self, dout):\n",
    "        \n",
    "#         self.dW = np.zeros((self.hidden_size, self.hidden_size))\n",
    "#         self.dV = np.zeros((self.input_size, self.hidden_size))\n",
    "#         self.dU = np.zeros((self.hidden_size, self.input_size))\n",
    "#         self.db1 = np.zeros((self.hidden_size, 1))\n",
    "#         self.db2 = np.zeros((self.input_size, 1))\n",
    "        \n",
    "#         index = self.seq_len - 1\n",
    "        \n",
    "#         delta = np.dot(self.V.T, dout)\n",
    "        \n",
    "#         delta[self.masks[index]] = 0\n",
    "        \n",
    "#         self.dV += np.dot(dout, self.s[index].reshape(-1, 1).T)\n",
    "#         self.db2 += dout\n",
    "#         self.db1 += delta\n",
    "        \n",
    "#         self.dW += np.dot(delta, self.s[index-1].reshape(-1, 1).T)\n",
    "#         self.dU += np.dot(delta, self.x[index].reshape(-1, 1).T)\n",
    "        \n",
    "# #         print('dout')\n",
    "# #         print(dout)\n",
    "        \n",
    "# #         print('dW', self.dW)\n",
    "# #         print(self.masks)\n",
    "        \n",
    "#         index -= 1\n",
    "#         while index >= 0:\n",
    "#             delta = np.dot(self.W.T, delta)\n",
    "            \n",
    "#             delta[self.masks[index]] = 0\n",
    "            \n",
    "# #             print('delta {} in index {}'.format(delta, index))\n",
    "                  \n",
    "#             self.db1 += delta\n",
    "#             self.dW += np.dot(delta, self.s[index-1].reshape(-1, 1).T)\n",
    "#             self.dU += np.dot(delta, self.x[index].reshape(-1, 1).T)\n",
    "            \n",
    "#             index -= 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 64\n",
    "input_size = 196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.BasicRNN object at 0x000001D48237BCC8>\n",
      "<__main__.Linear object at 0x000001D48237BD88>\n",
      "<__main__.softmax object at 0x000001D48237B408>\n"
     ]
    }
   ],
   "source": [
    "model = []\n",
    "\n",
    "model.append(BasicRNN(input_size=input_size, hidden_size=hidden_size))\n",
    "model.append(Linear(input_size, 10))\n",
    "model.append(softmax())\n",
    "\n",
    "for layer in model:\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "\n",
    "        for layer in self.model[0:1]:\n",
    "            \n",
    "            x = layer.forward(x)\n",
    "            \n",
    "        x = x.reshape(-1, 1)\n",
    "        \n",
    "        x = model[-2].forward(x)\n",
    "        \n",
    "        x = model[-1].forward(x, y)\n",
    "        return x\n",
    "    \n",
    "    def backward(self):\n",
    "        dout = model[-1].backward()\n",
    "        \n",
    "        index = len(model) - 2\n",
    "        while index >= 0:\n",
    "            dout = model[index].backward(dout)\n",
    "            index -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/10 loss: 0.6521910283069609\n",
      "Valid Acc: 0.8035833333333333\n",
      "get new model!\n",
      "epoch: 2/10 loss: 0.6380013008001708\n",
      "Valid Acc: 0.7979166666666667\n",
      "epoch: 3/10 loss: 0.6302357674293962\n",
      "Valid Acc: 0.8064166666666667\n",
      "get new model!\n",
      "epoch: 4/10 loss: 0.6290586725294811\n",
      "Valid Acc: 0.8153333333333334\n",
      "get new model!\n",
      "epoch: 5/10 loss: 0.6009265277245684\n",
      "Valid Acc: 0.8205833333333333\n",
      "get new model!\n",
      "epoch: 6/10 loss: 0.6045770307186197\n",
      "Valid Acc: 0.8146666666666667\n",
      "epoch: 7/10 loss: 0.6124661205691686\n",
      "Valid Acc: 0.8081666666666667\n",
      "epoch: 8/10 loss: 0.5944326459443773\n",
      "Valid Acc: 0.8334166666666667\n",
      "get new model!\n",
      "epoch: 9/10 loss: 0.569877530438788\n",
      "Valid Acc: 0.827\n",
      "epoch: 10/10 loss: 0.5942099946925434\n",
      "Valid Acc: 0.8019166666666667\n",
      "Test Acc: 0.8284\n"
     ]
    }
   ],
   "source": [
    "net = RNN(model=model)\n",
    "best_model = None\n",
    "best_acc = -1\n",
    "\n",
    "epochs = 10\n",
    "lr = 0.01\n",
    "for epoch in range(epochs):\n",
    "    loss = 0\n",
    "    for i in range(len(X_train)):\n",
    "\n",
    "        loss += net.forward(X_train[i].reshape(int(784/input_size), input_size), MakeOneHot(10, y_train[i]))\n",
    "        net.backward()\n",
    "        \n",
    "        # update parameters\n",
    "        index = len(net.model) - 2\n",
    "        while index >= 0:\n",
    "            if net.model[index].type == 'linear':\n",
    "                \n",
    "                net.model[index].w -= lr * net.model[index].dw\n",
    "                net.model[index].b -= lr * net.model[index].db\n",
    "            if net.model[index].type == 'basic_rnn':\n",
    "                \n",
    "#                 print('dW ', net.model[index].dW, 'dU', net.model[index].dU, 'dV', net.model[index].dV, net.model[index].db1, net.model[index].db2)\n",
    "                \n",
    "#                 print('before')\n",
    "#                 print(net.model[index].W, net.model[index].U, net.model[index].V)\n",
    "                \n",
    "#                 t[t > clip_value_max] = clip_value_max\n",
    "#                 t[t < clip_value_min] = clip_value_min\n",
    "                \n",
    "                net.model[index].W -= lr * net.model[index].dW\n",
    "                net.model[index].U -= lr * net.model[index].dU\n",
    "                net.model[index].V -= lr * net.model[index].dV\n",
    "                net.model[index].b1 -= lr * net.model[index].db1\n",
    "                net.model[index].b2 -= lr * net.model[index].db2\n",
    "                \n",
    "#                 print('after')\n",
    "#                 print(net.model[index].W, net.model[index].U, net.model[index].V)\n",
    "                \n",
    "                \n",
    "            index -= 1\n",
    "        \n",
    "    print(\"epoch: {}/{} loss: {}\".format(epoch + 1, epochs, loss / len(X_train)))\n",
    "\n",
    "    valid_correct = 0\n",
    "    for i in range(len(X_valid)):\n",
    "        net.forward(X_valid[i].reshape(int(784/input_size), input_size), MakeOneHot(10, y_valid[i]))\n",
    "        \n",
    "        if np.argmax(net.model[-1].p) == y_valid[i]:\n",
    "            valid_correct += 1\n",
    "    \n",
    "    acc = valid_correct / len(X_valid)\n",
    "    print(\"Valid Acc: {}\".format(acc))\n",
    "    if best_acc < acc:\n",
    "        best_acc = acc\n",
    "        best_model = copy.deepcopy(model)\n",
    "        print(\"get new model!\")\n",
    "\n",
    "test_net = RNN(best_model)\n",
    "test_correct = 0\n",
    "for i in range(len(X_test)):\n",
    "    test_net.forward(X_test[i].reshape(int(784/input_size), input_size), MakeOneHot(10, y_test[i]))\n",
    "\n",
    "    if np.argmax(net.model[-1].p) == y_test[i]:\n",
    "        test_correct += 1\n",
    "print(\"Test Acc: {}\".format(test_correct / len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
