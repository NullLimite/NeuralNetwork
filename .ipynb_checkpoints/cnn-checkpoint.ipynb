{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "import pickle\n",
    "\n",
    "data = loadmat('ex3data1.mat')\n",
    "\n",
    "\n",
    "X = data['X']\n",
    "Y = data['y']\n",
    "\n",
    "for i in range(len(Y)):\n",
    "    if Y[i][0] == 10:\n",
    "        Y[i] = 0\n",
    "    else:\n",
    "        Y[i] = Y[i][0]\n",
    "\n",
    "labels = []\n",
    "for label in Y:\n",
    "     labels.append(label[0])\n",
    "        \n",
    "X_sparse = coo_matrix(X)\n",
    "\n",
    "X, X_sparse, labels = shuffle(X, X_sparse, labels, random_state=0)\n",
    "\n",
    "\n",
    "for i in range(len(X)):\n",
    "#     m = X[i].mean()\n",
    "#     X[i] = X[i] - m\n",
    "    x_min, x_max = X[i].min(), X[i].max()\n",
    "    X[i] = (X[i]-x_min)/(x_max-x_min)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, labels, test_size=0.2, random_state=0)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[6].reshape(1, 20, 20).transpose(0, 2, 1).reshape(20, 20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.04307477 0.04307477 0.04307477 0.04307477 0.04307477 0.04307477\n",
      "  0.04307477 0.04307477 0.04307477 0.04307477 0.04307477 0.04307477\n",
      "  0.04307477 0.04307477 0.04307477 0.04307477 0.04307477 0.04307477\n",
      "  0.04307477 0.04307477]\n",
      " [0.04307477 0.04307477 0.04307477 0.04307477 0.04307477 0.04307477\n",
      "  0.04307477 0.04307477 0.04307477 0.04307477 0.04307477 0.04307477\n",
      "  0.04307477 0.04307477 0.04307477 0.04307477 0.04307477 0.04307477\n",
      "  0.04307477 0.04307477]\n",
      " [0.04307477 0.04307477 0.04307477 0.04307477 0.04307477 0.04307477\n",
      "  0.04307477 0.04307477 0.04307477 0.04307477 0.04307477 0.04307477\n",
      "  0.04307477 0.04307477 0.04307477 0.04307477 0.04307477 0.04307477\n",
      "  0.04307477 0.04307477]\n",
      " [0.04307477 0.04307477 0.04307477 0.04307477 0.04307477 0.04316329\n",
      "  0.04218347 0.03774345 0.03858176 0.04215146 0.04312644 0.04307826\n",
      "  0.04310936 0.04287582 0.04067621 0.04019329 0.04317471 0.04308147\n",
      "  0.04307477 0.04307477]\n",
      " [0.04307477 0.04307477 0.04307477 0.04308567 0.04398695 0.03309377\n",
      "  0.02408865 0.07552276 0.06430629 0.02458742 0.02423056 0.03005599\n",
      "  0.03444806 0.02285567 0.03834615 0.05190437 0.04022581 0.04332026\n",
      "  0.04307477 0.04307477]\n",
      " [0.04307477 0.04307477 0.04307477 0.04310892 0.0351694  0.08461592\n",
      "  0.35680373 0.87141727 0.78779068 0.36065302 0.1512442  0.11025995\n",
      "  0.0647827  0.21807162 0.5593316  0.55515477 0.04272258 0.04006077\n",
      "  0.04307477 0.04307477]\n",
      " [0.04307477 0.04307477 0.04307477 0.04173581 0.02609606 0.44839952\n",
      "  0.94476003 0.95248952 0.98111316 0.94755868 0.80597406 0.74058475\n",
      "  0.67629304 0.84250689 0.99517484 0.79246323 0.10669043 0.03199926\n",
      "  0.04307477 0.04307477]\n",
      " [0.04307477 0.04307477 0.04307477 0.03453822 0.13744731 0.80182213\n",
      "  0.97790387 0.85030615 0.49528167 0.56661362 0.84895979 0.86331607\n",
      "  0.87456457 0.96434807 0.94353553 0.51773649 0.04133556 0.0402144\n",
      "  0.04307477 0.04307477]\n",
      " [0.04307477 0.04307477 0.04307477 0.0291788  0.22717626 0.95113419\n",
      "  0.94238042 0.43947701 0.0055189  0.03544668 0.08410864 0.06823276\n",
      "  0.35814132 0.98479271 0.62364669 0.05206859 0.03734465 0.04332026\n",
      "  0.04307477 0.04307477]\n",
      " [0.04307477 0.04307477 0.04307477 0.03847334 0.09089498 0.49582913\n",
      "  0.51301767 0.08674601 0.03499968 0.042808   0.02208198 0.11755222\n",
      "  0.77659077 0.99534015 0.45700236 0.02539185 0.04170091 0.04307477\n",
      "  0.04307477 0.04307477]\n",
      " [0.04307477 0.04307477 0.04307477 0.04341084 0.03742175 0.03474325\n",
      "  0.04067697 0.04029636 0.04315413 0.03163494 0.10278549 0.63928793\n",
      "  0.98231854 0.81588975 0.19083743 0.02417196 0.04294832 0.04307477\n",
      "  0.04307477 0.04307477]\n",
      " [0.04307477 0.04307477 0.04307477 0.04308553 0.04304099 0.04112415\n",
      "  0.0407947  0.04284755 0.0437005  0.         0.27415036 0.98776671\n",
      "  0.94629872 0.42924443 0.0313042  0.04036358 0.04308847 0.04307477\n",
      "  0.04307477 0.04307477]\n",
      " [0.04307477 0.04307477 0.04307477 0.04307477 0.04307477 0.04307477\n",
      "  0.04307477 0.04312822 0.03384223 0.14433611 0.73136188 0.98756825\n",
      "  0.62883017 0.04916111 0.03702687 0.0434631  0.04307477 0.04307477\n",
      "  0.04307477 0.04307477]\n",
      " [0.04307477 0.04307477 0.04307477 0.04307477 0.04307477 0.04307477\n",
      "  0.04309341 0.04325108 0.00914284 0.52008623 0.98038722 0.89968481\n",
      "  0.23764817 0.02083548 0.04358728 0.04307477 0.04307477 0.04307477\n",
      "  0.04307477 0.04307477]\n",
      " [0.04307477 0.04307477 0.04307477 0.04307477 0.04307477 0.04307477\n",
      "  0.04345154 0.02476192 0.11467372 0.74483344 0.99920073 0.59548009\n",
      "  0.04344823 0.03721272 0.04307477 0.04307477 0.04307477 0.04307477\n",
      "  0.04307477 0.04307477]\n",
      " [0.04307477 0.04307477 0.04307477 0.04307477 0.04307477 0.04307477\n",
      "  0.03666324 0.06542844 0.57388075 0.98118641 0.8144833  0.15395312\n",
      "  0.02701121 0.04307958 0.04307477 0.04307477 0.04307477 0.04307477\n",
      "  0.04307477 0.04307477]\n",
      " [0.04307477 0.04307477 0.04307477 0.04307477 0.04307477 0.04336597\n",
      "  0.02148761 0.34580419 0.95700809 0.92499264 0.38132365 0.00941568\n",
      "  0.04382046 0.04310925 0.04307477 0.04307477 0.04307477 0.04307477\n",
      "  0.04307477 0.04307477]\n",
      " [0.04307477 0.04307477 0.04307477 0.04307477 0.04307477 0.03163387\n",
      "  0.15458498 0.81004822 1.         0.51657491 0.02755234 0.04138946\n",
      "  0.04307477 0.04307477 0.04307477 0.04307477 0.04307477 0.04307477\n",
      "  0.04307477 0.04307477]\n",
      " [0.04307477 0.04307477 0.04307477 0.04307477 0.04307477 0.02819445\n",
      "  0.19310264 0.92859937 0.87950647 0.2533923  0.02430052 0.0426806\n",
      "  0.04307477 0.04307477 0.04307477 0.04307477 0.04307477 0.04307477\n",
      "  0.04307477 0.04307477]\n",
      " [0.04307477 0.04307477 0.04307477 0.04307477 0.04307477 0.03917269\n",
      "  0.08231409 0.28349953 0.21246201 0.03874754 0.04070091 0.04313068\n",
      "  0.04307477 0.04307477 0.04307477 0.04307477 0.04307477 0.04307477\n",
      "  0.04307477 0.04307477]]\n",
      "0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only for one example\n",
    "class Linear:\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        self.w = np.random.randn(output_dim, input_dim)\n",
    "        self.b = np.random.randn(output_dim, 1)\n",
    "        self.x = None\n",
    "        self.dw = None\n",
    "        self.db = None\n",
    "        \n",
    "        self.type = 'linear'\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        \n",
    "        out = np.dot(self.w, x) + self.b\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        self.dw = np.dot(dout, self.x.T)\n",
    "        self.db = dout\n",
    "        \n",
    "        return np.dot(self.w.T, dout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only for one example\n",
    "class ReLU:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "        \n",
    "        self.type = 'relu'\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.mask = (x <= 0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        \n",
    "        dout[self.mask] = 0\n",
    "        return dout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only for one example\n",
    "class softmax:\n",
    "    def __init__(self):\n",
    "        self.p = None\n",
    "        self.t = None\n",
    "    \n",
    "    def forward(self, a, t):\n",
    "        self.t = t\n",
    "        c = np.max(a)\n",
    "        exp_a = np.exp(a - c)\n",
    "        sum_exp_a = np.sum(exp_a)\n",
    "        p = exp_a / sum_exp_a\n",
    "        \n",
    "        self.p = p\n",
    "        \n",
    "        _p = np.log(p + 1e-5)\n",
    "\n",
    "        loss = np.sum(-_p*t)\n",
    "        \n",
    "        return loss\n",
    "    def backward(self):\n",
    "        \n",
    "        return self.p - self.t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only for one example\n",
    "class Conv2d:\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "        '''\n",
    "            kernel_size (h, w)\n",
    "        '''\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        \n",
    "        self.b = np.fabs(np.random.randn(self.out_channels, 1))\n",
    "        self.w = np.fabs(np.random.randn(self.out_channels, self.in_channels, kernel_size[0], kernel_size[1]))\n",
    "\n",
    "        self.dw = None\n",
    "        self.db = None\n",
    "        self.x = None\n",
    "        \n",
    "        self.type = 'conv2d'\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        '''\n",
    "            x numpy array of (1, h, w)\n",
    "        '''\n",
    "        \n",
    "        if x.ndim == 2:\n",
    "            x = x.reshape(-1, x.shape[0], x.shape[1])\n",
    "       \n",
    "        x = np.pad(x, ((0, 0), (self.padding, self.padding), (self.padding, self.padding)), 'constant', constant_values=0)\n",
    "        \n",
    "        _, in_h, in_w = x.shape\n",
    "        \n",
    "        out_h = 1 + int((in_h + 2*self.padding - self.kernel_size[0]) / self.stride)\n",
    "        out_w = 1 + int((in_w + 2*self.padding - self.kernel_size[1]) / self.stride)\n",
    "        \n",
    "        _x = []\n",
    "        for i in range(out_h):\n",
    "            for j in range(out_w):\n",
    "                h_start = i * self.stride\n",
    "                h_end = h_start + self.kernel_size[0]\n",
    "                w_start = j * self.stride\n",
    "                w_end = w_start + self.kernel_size[1]\n",
    "                \n",
    "                temp = x[:, h_start:h_end, w_start:w_end]\n",
    "\n",
    "                _x.append(np.squeeze(np.reshape(temp, (1, 1, -1))))\n",
    "        _x = np.array(_x)\n",
    "        \n",
    "        self.w = np.reshape(self.w, (self.out_channels, -1))\n",
    "        self.x = _x.T\n",
    "        \n",
    "        out = np.dot(self.w, self.x)\n",
    "        \n",
    "        out += self.b\n",
    "        \n",
    "        out = out.reshape(self.out_channels, out_h, out_w)\n",
    "        \n",
    "        # this line\n",
    "        self.db = np.zeros((self.out_channels, 1))\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        \n",
    "        # this line\n",
    "        dout = dout.reshape(-1, self.x.T.shape[0])\n",
    "        \n",
    "        self.dw = np.dot(dout, self.x.T)\n",
    "        \n",
    "#         for i in range(self.out_channels):\n",
    "#             self.db[i, 0] += np.sum(dout[i])\n",
    "        \n",
    "        return np.dot(self.w.T, dout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool2d:\n",
    "    def __init__(self, kernel_size, stride):\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.arg_max = None\n",
    "        self.shape = None\n",
    "        self.type = 'maxpool2d'\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        in_channels, in_h, in_w = x.shape\n",
    "        \n",
    "        out_h = int(1 + (in_h - self.kernel_size[0]) / self.stride)\n",
    "        out_w = int(1 + (in_w - self.kernel_size[1]) / self.stride)\n",
    "        \n",
    "        _x = []\n",
    "        for i in range(in_channels): \n",
    "            for j in range(out_h):\n",
    "                for k in range(out_w):\n",
    "                    h_start = j * self.stride\n",
    "                    h_end = h_start + self.kernel_size[0]\n",
    "                    w_start = k * self.stride\n",
    "                    w_end = w_start + self.kernel_size[1]\n",
    "                \n",
    "                    temp = x[i, h_start:h_end, w_start:w_end]\n",
    "\n",
    "                    _x.append(np.squeeze(np.reshape(temp, (1, -1))))\n",
    "        _x = np.array(_x)\n",
    "        \n",
    "        self.shape = x.shape\n",
    "        \n",
    "        out = np.max(_x, axis=1)\n",
    "        \n",
    "        self.arg_max = np.argmax(_x, axis=1)\n",
    "        \n",
    "        return out.reshape(in_channels, out_h, out_w)\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dout = np.squeeze(dout.reshape(1, -1))\n",
    "        \n",
    "        _dout = np.zeros(self.shape)\n",
    "        \n",
    "        index = 0\n",
    "        \n",
    "        in_channels, in_h, in_w = self.shape\n",
    "        \n",
    "        out_h = int(1 + (in_h - self.kernel_size[0]) / self.stride)\n",
    "        out_w = int(1 + (in_w - self.kernel_size[1]) / self.stride)\n",
    "        \n",
    "        for i in range(in_channels): \n",
    "            for j in range(out_h):\n",
    "                for k in range(out_w):\n",
    "                    h_start = j * self.stride\n",
    "                    h_end = h_start + self.kernel_size[0]\n",
    "                    w_start = k * self.stride\n",
    "                    w_end = w_start + self.kernel_size[1]\n",
    "                \n",
    "                    p = h_start + int(self.arg_max[index] /  self.kernel_size[0])\n",
    "                    q = w_start + self.arg_max[index] % self.kernel_size[1]\n",
    "                    \n",
    "                    _dout[i, p, q] = dout[index]\n",
    "                    \n",
    "                    index += 1\n",
    "        \n",
    "        return _dout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeOneHot(class_num, x):\n",
    "    true = np.zeros(class_num)\n",
    "    true[x] = 1\n",
    "    return true.reshape(class_num, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Conv2d object at 0x0000018D16ED2F48>\n",
      "<__main__.ReLU object at 0x0000018D16ED2548>\n",
      "<__main__.MaxPool2d object at 0x0000018D16ED2448>\n",
      "<__main__.Linear object at 0x0000018D16ED2588>\n",
      "<__main__.softmax object at 0x0000018D172A3AC8>\n"
     ]
    }
   ],
   "source": [
    "model = []\n",
    "\n",
    "model.append(Conv2d(1, 1, (2, 2)))\n",
    "model.append(ReLU())\n",
    "model.append(MaxPool2d((2, 2), 2))\n",
    "\n",
    "model.append(Linear(81, 10))\n",
    "\n",
    "model.append(softmax())\n",
    "\n",
    "for layer in model:\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "\n",
    "        for layer in self.model[0:-2]:\n",
    "            \n",
    "            x = layer.forward(x)\n",
    "            \n",
    "        x = x.reshape(-1, 1)\n",
    "        x = model[-2].forward(x)\n",
    "        \n",
    "        x = model[-1].forward(x, y)\n",
    "        return x\n",
    "    \n",
    "    def backward(self):\n",
    "        dout = model[-1].backward()\n",
    "        \n",
    "        index = len(model) - 2\n",
    "        while index >= 0:\n",
    "            dout = model[index].backward(dout)\n",
    "            index -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/500 loss: 1.2741828725141342\n",
      "Valid Acc: 0.745\n",
      "get new model!\n",
      "epoch: 2/500 loss: 0.6194862350054513\n",
      "Valid Acc: 0.79\n",
      "get new model!\n",
      "epoch: 3/500 loss: 0.5448626775533818\n",
      "Valid Acc: 0.805\n",
      "get new model!\n",
      "epoch: 4/500 loss: 0.5108608121346327\n",
      "Valid Acc: 0.805\n",
      "epoch: 5/500 loss: 0.48986513470008936\n",
      "Valid Acc: 0.80375\n",
      "epoch: 6/500 loss: 0.4754599915543193\n",
      "Valid Acc: 0.80625\n",
      "get new model!\n",
      "epoch: 7/500 loss: 0.4638436357458247\n",
      "Valid Acc: 0.81125\n",
      "get new model!\n",
      "epoch: 8/500 loss: 0.454150617355548\n",
      "Valid Acc: 0.81125\n",
      "epoch: 9/500 loss: 0.44962962285642727\n",
      "Valid Acc: 0.8125\n",
      "get new model!\n",
      "epoch: 10/500 loss: 0.4422902692816129\n",
      "Valid Acc: 0.80875\n",
      "epoch: 11/500 loss: 0.43622157318737903\n",
      "Valid Acc: 0.8075\n",
      "epoch: 12/500 loss: 0.43142941875505236\n",
      "Valid Acc: 0.805\n",
      "epoch: 13/500 loss: 0.4276857996518948\n",
      "Valid Acc: 0.8025\n",
      "epoch: 14/500 loss: 0.42342450252207153\n",
      "Valid Acc: 0.805\n",
      "epoch: 15/500 loss: 0.4200329565169676\n",
      "Valid Acc: 0.80375\n",
      "epoch: 16/500 loss: 0.41782825687561376\n",
      "Valid Acc: 0.805\n",
      "epoch: 17/500 loss: 0.41520087635585035\n",
      "Valid Acc: 0.80375\n",
      "epoch: 18/500 loss: 0.4124021253378637\n",
      "Valid Acc: 0.8025\n",
      "epoch: 19/500 loss: 0.4107372199417088\n",
      "Valid Acc: 0.80125\n",
      "epoch: 20/500 loss: 0.408894559597663\n",
      "Valid Acc: 0.8\n",
      "epoch: 21/500 loss: 0.4070512193527241\n",
      "Valid Acc: 0.8\n",
      "epoch: 22/500 loss: 0.4052167516249818\n",
      "Valid Acc: 0.80125\n",
      "epoch: 23/500 loss: 0.4034953497975865\n",
      "Valid Acc: 0.8025\n",
      "epoch: 24/500 loss: 0.40178948956782934\n",
      "Valid Acc: 0.8\n",
      "epoch: 25/500 loss: 0.40020424153808487\n",
      "Valid Acc: 0.8\n",
      "epoch: 26/500 loss: 0.39923829318228843\n",
      "Valid Acc: 0.8\n",
      "epoch: 27/500 loss: 0.3981292788689361\n",
      "Valid Acc: 0.79875\n",
      "epoch: 28/500 loss: 0.3973630699995047\n",
      "Valid Acc: 0.79875\n",
      "epoch: 29/500 loss: 0.3961164749879941\n",
      "Valid Acc: 0.79625\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-139-015f7ccb8fdd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMakeOneHot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-138-8357daf34b1d>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-122-47c543b4fc66>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     46\u001b[0m                 \u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh_start\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mh_end\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw_start\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mw_end\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m                 \u001b[0m_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m         \u001b[0m_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\yuchen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(a, newshape, order)\u001b[0m\n\u001b[0;32m    299\u001b[0m            [5, 6]])\n\u001b[0;32m    300\u001b[0m     \"\"\"\n\u001b[1;32m--> 301\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'reshape'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\yuchen\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net = CNN(model=model)\n",
    "\n",
    "best_model = None\n",
    "best_acc = -1\n",
    "\n",
    "epochs = 30\n",
    "lr = 0.1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss = 0\n",
    "    for i in range(len(X_train)):\n",
    "\n",
    "        loss += net.forward(X_train[i].reshape(1, 20, 20).transpose(0, 2, 1), MakeOneHot(10, y_train[i]))\n",
    "        net.backward()\n",
    "        \n",
    "        # update parameters\n",
    "        index = len(net.model) - 2\n",
    "        while index >= 0:\n",
    "            if net.model[index].type == 'linear' or net.model[index].type == 'conv2d':\n",
    "                \n",
    "                net.model[index].w -= lr * net.model[index].dw\n",
    "                net.model[index].b -= lr * net.model[index].db\n",
    "                \n",
    "            index -= 1\n",
    "        \n",
    "    print(\"epoch: {}/{} loss: {}\".format(epoch + 1, epochs, loss / len(X_train)))\n",
    "\n",
    "    valid_correct = 0\n",
    "    for i in range(len(X_valid)):\n",
    "        net.forward(X_valid[i].reshape(1, 20, 20).transpose(0, 2, 1), MakeOneHot(10, y_valid[i]))\n",
    "        \n",
    "        if np.argmax(net.model[-1].p) == y_valid[i]:\n",
    "            valid_correct += 1\n",
    "    \n",
    "    acc = valid_correct / len(X_valid)\n",
    "    print(\"Valid Acc: {}\".format(acc))\n",
    "    if best_acc < acc:\n",
    "        best_acc = acc\n",
    "        best_model = copy.deepcopy(model)\n",
    "        print(\"get new model!\")\n",
    "\n",
    "test_net = CNN(best_model)\n",
    "test_correct = 0\n",
    "for i in range(len(X_test)):\n",
    "    test_net.forward(X_test[i].reshape(1, 20, 20).transpose(0, 2, 1), MakeOneHot(10, y_test[i]))\n",
    "\n",
    "    if np.argmax(net.model[-1].p) == y_test[i]:\n",
    "        test_correct += 1\n",
    "print(\"Test Acc: {}\".format(test_correct / len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
