{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "import pickle\n",
    "\n",
    "data = loadmat('ex3data1.mat')\n",
    "\n",
    "\n",
    "X = data['X']\n",
    "Y = data['y']\n",
    "\n",
    "for i in range(len(Y)):\n",
    "    if Y[i][0] == 10:\n",
    "        Y[i] = 0\n",
    "    else:\n",
    "        Y[i] = Y[i][0]\n",
    "\n",
    "labels = []\n",
    "for label in Y:\n",
    "     labels.append(label[0])\n",
    "        \n",
    "X_sparse = coo_matrix(X)\n",
    "\n",
    "X, X_sparse, labels = shuffle(X, X_sparse, labels, random_state=0)\n",
    "\n",
    "\n",
    "for i in range(len(X)):\n",
    "#     m = X[i].mean()\n",
    "#     X[i] = X[i] - m\n",
    "    x_min, x_max = X[i].min(), X[i].max()\n",
    "    X[i] = (X[i]-x_min)/(x_max-x_min)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, labels, test_size=0.2, random_state=0)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[6].reshape(1, 20, 20).transpose(0, 2, 1).reshape(20, 20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only for one example\n",
    "class Linear:\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        self.w = np.random.randn(output_dim, input_dim)\n",
    "        self.b = np.random.randn(output_dim, 1)\n",
    "        self.x = None\n",
    "        self.dw = None\n",
    "        self.db = None\n",
    "        \n",
    "        self.type = 'linear'\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        \n",
    "        out = np.dot(self.w, x) + self.b\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        self.dw = np.dot(dout, self.x.T)\n",
    "        self.db = dout\n",
    "        \n",
    "        return np.dot(self.w.T, dout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only for one example\n",
    "class ReLU:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "        \n",
    "        self.type = 'relu'\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.mask = (x <= 0)\n",
    "        out = x.copy()\n",
    "        out[self.mask] = 0\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        \n",
    "        dout[self.mask] = 0\n",
    "        return dout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only for one example\n",
    "class softmax:\n",
    "    def __init__(self):\n",
    "        self.p = None\n",
    "        self.t = None\n",
    "    \n",
    "    def forward(self, a, t):\n",
    "        self.t = t\n",
    "        c = np.max(a)\n",
    "        exp_a = np.exp(a - c)\n",
    "        sum_exp_a = np.sum(exp_a)\n",
    "        p = exp_a / sum_exp_a\n",
    "        \n",
    "        self.p = p\n",
    "        \n",
    "        _p = np.log(p + 1e-5)\n",
    "\n",
    "        loss = np.sum(-_p*t)\n",
    "        \n",
    "        return loss\n",
    "    def backward(self):\n",
    "        \n",
    "        return self.p - self.t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only for one example\n",
    "class Conv2d:\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "        '''\n",
    "            kernel_size (h, w)\n",
    "        '''\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        \n",
    "        self.b = np.fabs(np.random.randn(self.out_channels, 1))\n",
    "        self.w = np.fabs(np.random.randn(self.out_channels, self.in_channels, kernel_size[0], kernel_size[1]))\n",
    "\n",
    "        self.dw = None\n",
    "        self.db = None\n",
    "        self.x = None\n",
    "        \n",
    "        self.type = 'conv2d'\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        '''\n",
    "            x numpy array of (1, h, w)\n",
    "        '''\n",
    "        \n",
    "        if x.ndim == 2:\n",
    "            x = x.reshape(-1, x.shape[0], x.shape[1])\n",
    "       \n",
    "        x = np.pad(x, ((0, 0), (self.padding, self.padding), (self.padding, self.padding)), 'constant', constant_values=0)\n",
    "        \n",
    "        _, in_h, in_w = x.shape\n",
    "        \n",
    "        out_h = 1 + int((in_h + 2*self.padding - self.kernel_size[0]) / self.stride)\n",
    "        out_w = 1 + int((in_w + 2*self.padding - self.kernel_size[1]) / self.stride)\n",
    "        \n",
    "        _x = []\n",
    "        for i in range(out_h):\n",
    "            for j in range(out_w):\n",
    "                h_start = i * self.stride\n",
    "                h_end = h_start + self.kernel_size[0]\n",
    "                w_start = j * self.stride\n",
    "                w_end = w_start + self.kernel_size[1]\n",
    "                \n",
    "                temp = x[:, h_start:h_end, w_start:w_end]\n",
    "\n",
    "                _x.append(np.squeeze(np.reshape(temp, (1, 1, -1))))\n",
    "        _x = np.array(_x)\n",
    "        \n",
    "        self.w = np.reshape(self.w, (self.out_channels, -1))\n",
    "        self.x = _x.T\n",
    "        \n",
    "        out = np.dot(self.w, self.x)\n",
    "        \n",
    "        out += self.b\n",
    "        \n",
    "        out = out.reshape(self.out_channels, out_h, out_w)\n",
    "        \n",
    "        # this line\n",
    "        self.db = np.zeros((self.out_channels, 1))\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        \n",
    "        # this line\n",
    "        dout = dout.reshape(-1, self.x.T.shape[0])\n",
    "        \n",
    "        self.dw = np.dot(dout, self.x.T)\n",
    "        \n",
    "#         for i in range(self.out_channels):\n",
    "#             self.db[i, 0] += np.sum(dout[i])\n",
    "        \n",
    "        return np.dot(self.w.T, dout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool2d:\n",
    "    def __init__(self, kernel_size, stride):\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.arg_max = None\n",
    "        self.shape = None\n",
    "        self.type = 'maxpool2d'\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        in_channels, in_h, in_w = x.shape\n",
    "        \n",
    "        out_h = int(1 + (in_h - self.kernel_size[0]) / self.stride)\n",
    "        out_w = int(1 + (in_w - self.kernel_size[1]) / self.stride)\n",
    "        \n",
    "        _x = []\n",
    "        for i in range(in_channels): \n",
    "            for j in range(out_h):\n",
    "                for k in range(out_w):\n",
    "                    h_start = j * self.stride\n",
    "                    h_end = h_start + self.kernel_size[0]\n",
    "                    w_start = k * self.stride\n",
    "                    w_end = w_start + self.kernel_size[1]\n",
    "                \n",
    "                    temp = x[i, h_start:h_end, w_start:w_end]\n",
    "\n",
    "                    _x.append(np.squeeze(np.reshape(temp, (1, -1))))\n",
    "        _x = np.array(_x)\n",
    "        \n",
    "        self.shape = x.shape\n",
    "        \n",
    "        out = np.max(_x, axis=1)\n",
    "        \n",
    "        self.arg_max = np.argmax(_x, axis=1)\n",
    "        \n",
    "        return out.reshape(in_channels, out_h, out_w)\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        dout = np.squeeze(dout.reshape(1, -1))\n",
    "        \n",
    "        _dout = np.zeros(self.shape)\n",
    "        \n",
    "        index = 0\n",
    "        \n",
    "        in_channels, in_h, in_w = self.shape\n",
    "        \n",
    "        out_h = int(1 + (in_h - self.kernel_size[0]) / self.stride)\n",
    "        out_w = int(1 + (in_w - self.kernel_size[1]) / self.stride)\n",
    "        \n",
    "        for i in range(in_channels): \n",
    "            for j in range(out_h):\n",
    "                for k in range(out_w):\n",
    "                    h_start = j * self.stride\n",
    "                    h_end = h_start + self.kernel_size[0]\n",
    "                    w_start = k * self.stride\n",
    "                    w_end = w_start + self.kernel_size[1]\n",
    "                \n",
    "                    p = h_start + int(self.arg_max[index] /  self.kernel_size[0])\n",
    "                    q = w_start + self.arg_max[index] % self.kernel_size[1]\n",
    "                    \n",
    "                    _dout[i, p, q] = dout[index]\n",
    "                    \n",
    "                    index += 1\n",
    "        \n",
    "        return _dout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeOneHot(class_num, x):\n",
    "    true = np.zeros(class_num)\n",
    "    true[x] = 1\n",
    "    return true.reshape(class_num, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Conv2d object at 0x0000018D172E7848>\n",
      "<__main__.ReLU object at 0x0000018D172E9AC8>\n",
      "<__main__.MaxPool2d object at 0x0000018D172E95C8>\n",
      "<__main__.Linear object at 0x0000018D172E9A88>\n",
      "<__main__.softmax object at 0x0000018D172E9508>\n"
     ]
    }
   ],
   "source": [
    "model = []\n",
    "\n",
    "model.append(Conv2d(1, 1, (2, 2)))\n",
    "model.append(ReLU())\n",
    "model.append(MaxPool2d((2, 2), 2))\n",
    "\n",
    "model.append(Linear(81, 10))\n",
    "\n",
    "model.append(softmax())\n",
    "\n",
    "for layer in model:\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "\n",
    "        for layer in self.model[0:-2]:\n",
    "            \n",
    "            x = layer.forward(x)\n",
    "            \n",
    "        x = x.reshape(-1, 1)\n",
    "        x = model[-2].forward(x)\n",
    "        \n",
    "        x = model[-1].forward(x, y)\n",
    "        return x\n",
    "    \n",
    "    def backward(self):\n",
    "        dout = model[-1].backward()\n",
    "        \n",
    "        index = len(model) - 2\n",
    "        while index >= 0:\n",
    "            dout = model[index].backward(dout)\n",
    "            index -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/30 loss: 1.6781740804164966\n",
      "Valid Acc: 0.675\n",
      "get new model!\n",
      "epoch: 2/30 loss: 0.7779262204779473\n",
      "Valid Acc: 0.805\n",
      "get new model!\n",
      "epoch: 3/30 loss: 0.6135227806728563\n",
      "Valid Acc: 0.82\n",
      "get new model!\n",
      "epoch: 4/30 loss: 0.5499390322208463\n",
      "Valid Acc: 0.83375\n",
      "get new model!\n",
      "epoch: 5/30 loss: 0.51365645131551\n",
      "Valid Acc: 0.83\n",
      "epoch: 6/30 loss: 0.4890355906728884\n",
      "Valid Acc: 0.83625\n",
      "get new model!\n",
      "epoch: 7/30 loss: 0.4723103067332009\n",
      "Valid Acc: 0.835\n",
      "epoch: 8/30 loss: 0.4657184004472175\n",
      "Valid Acc: 0.84\n",
      "get new model!\n",
      "epoch: 9/30 loss: 0.4570881241361976\n",
      "Valid Acc: 0.84\n",
      "epoch: 10/30 loss: 0.44954247917315754\n",
      "Valid Acc: 0.83875\n",
      "epoch: 11/30 loss: 0.4444877339648597\n",
      "Valid Acc: 0.845\n",
      "get new model!\n",
      "epoch: 12/30 loss: 0.4292646813867209\n",
      "Valid Acc: 0.84875\n",
      "get new model!\n",
      "epoch: 13/30 loss: 0.42680298906174136\n",
      "Valid Acc: 0.84875\n",
      "epoch: 14/30 loss: 0.4229125257677282\n",
      "Valid Acc: 0.84875\n",
      "epoch: 15/30 loss: 0.41870543620022554\n",
      "Valid Acc: 0.85125\n",
      "get new model!\n",
      "epoch: 16/30 loss: 0.4887472816133107\n",
      "Valid Acc: 0.85\n",
      "epoch: 17/30 loss: 0.42319731949650224\n",
      "Valid Acc: 0.85125\n",
      "epoch: 18/30 loss: 0.4507208266799687\n",
      "Valid Acc: 0.85375\n",
      "get new model!\n",
      "epoch: 19/30 loss: 0.4134238296470252\n",
      "Valid Acc: 0.85375\n",
      "epoch: 20/30 loss: 0.40945809253662674\n",
      "Valid Acc: 0.84625\n",
      "epoch: 21/30 loss: 0.41102057152597254\n",
      "Valid Acc: 0.84875\n",
      "epoch: 22/30 loss: 0.406700682685446\n",
      "Valid Acc: 0.85375\n",
      "epoch: 23/30 loss: 0.40521369204044055\n",
      "Valid Acc: 0.84125\n",
      "epoch: 24/30 loss: 0.4008835474927135\n",
      "Valid Acc: 0.85\n",
      "epoch: 25/30 loss: 0.3912608078157222\n",
      "Valid Acc: 0.84875\n",
      "epoch: 26/30 loss: 0.40215248447924623\n",
      "Valid Acc: 0.84625\n",
      "epoch: 27/30 loss: 0.39621042327116085\n",
      "Valid Acc: 0.84625\n",
      "epoch: 28/30 loss: 0.39749334203541736\n",
      "Valid Acc: 0.85\n",
      "epoch: 29/30 loss: 0.38936045712444467\n",
      "Valid Acc: 0.85\n",
      "epoch: 30/30 loss: 0.39160681504121436\n",
      "Valid Acc: 0.84625\n",
      "Test Acc: 0.879\n"
     ]
    }
   ],
   "source": [
    "net = CNN(model=model)\n",
    "\n",
    "best_model = None\n",
    "best_acc = -1\n",
    "\n",
    "epochs = 30\n",
    "lr = 0.1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss = 0\n",
    "    for i in range(len(X_train)):\n",
    "\n",
    "        loss += net.forward(X_train[i].reshape(1, 20, 20).transpose(0, 2, 1), MakeOneHot(10, y_train[i]))\n",
    "        net.backward()\n",
    "        \n",
    "        # update parameters\n",
    "        index = len(net.model) - 2\n",
    "        while index >= 0:\n",
    "            if net.model[index].type == 'linear' or net.model[index].type == 'conv2d':\n",
    "                \n",
    "                net.model[index].w -= lr * net.model[index].dw\n",
    "                net.model[index].b -= lr * net.model[index].db\n",
    "                \n",
    "            index -= 1\n",
    "        \n",
    "    print(\"epoch: {}/{} loss: {}\".format(epoch + 1, epochs, loss / len(X_train)))\n",
    "\n",
    "    valid_correct = 0\n",
    "    for i in range(len(X_valid)):\n",
    "        net.forward(X_valid[i].reshape(1, 20, 20).transpose(0, 2, 1), MakeOneHot(10, y_valid[i]))\n",
    "        \n",
    "        if np.argmax(net.model[-1].p) == y_valid[i]:\n",
    "            valid_correct += 1\n",
    "    \n",
    "    acc = valid_correct / len(X_valid)\n",
    "    print(\"Valid Acc: {}\".format(acc))\n",
    "    if best_acc < acc:\n",
    "        best_acc = acc\n",
    "        best_model = copy.deepcopy(model)\n",
    "        print(\"get new model!\")\n",
    "\n",
    "test_net = CNN(best_model)\n",
    "test_correct = 0\n",
    "for i in range(len(X_test)):\n",
    "    test_net.forward(X_test[i].reshape(1, 20, 20).transpose(0, 2, 1), MakeOneHot(10, y_test[i]))\n",
    "\n",
    "    if np.argmax(net.model[-1].p) == y_test[i]:\n",
    "        test_correct += 1\n",
    "print(\"Test Acc: {}\".format(test_correct / len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
